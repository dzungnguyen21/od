{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.datasets import CocoDetection\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import transforms as T\n",
    "import torchvision.transforms.functional as F\n",
    "from pycocotools.coco import COCO\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import random\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read random image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Read folder\n",
    "root_folder = \"\"\n",
    "train_folder = os.path.join(root_folder + \"train2017\")\n",
    "image_files = [i for i in os.listdir(train_folder) if i.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n",
    "# Pick random 6 images\n",
    "random_images = random.sample(image_files, 6)\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "for i, img_name in enumerate(random_images):\n",
    "    img_path = os.path.join(train_folder, img_name)\n",
    "    img = cv2.imread(img_path)\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    plt.imshow(img_rgb)\n",
    "    plt.axis('off')\n",
    "    plt.title(img_name)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CocoDetectionDataset(CocoDetection):\n",
    "    def __init__(self, img_folder, ann_file, train=False):\n",
    "        super(CocoDetectionDataset, self).__init__(img_folder, ann_file)\n",
    "        self.train = train\n",
    "    def __getitem__(self, idx):\n",
    "        img, target = super(CocoDetectionDataset, self).__getitem__(idx)\n",
    "        \n",
    "        # Lấy kích thước ảnh gốc trước khi chuyển thành Tensor\n",
    "        image_width, image_height = img.size\n",
    "\n",
    "        # Kiểm tra nếu target rỗng (ảnh không có đối tượng nào)\n",
    "        if not target:\n",
    "            # Tạo các tensor rỗng với đúng shape\n",
    "            formatted_target = {\n",
    "                \"boxes\": torch.zeros((0, 4), dtype=torch.float32),\n",
    "                \"labels\": torch.zeros(0, dtype=torch.int64),\n",
    "                \"image_id\": torch.tensor([self.ids[idx]]),\n",
    "                \"area\": torch.zeros(0, dtype=torch.float32),\n",
    "                \"iscrowd\": torch.zeros(0, dtype=torch.int64)\n",
    "            }\n",
    "            # Chỉ cần chuyển ảnh sang tensor và trả về\n",
    "            img = F.to_tensor(img)\n",
    "            return img, formatted_target\n",
    "\n",
    "        # -- Phần xử lý target như cũ --\n",
    "        image_id = self.ids[idx]\n",
    "        boxes = [obj['bbox'] for obj in target]\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32).reshape(-1, 4)\n",
    "        boxes[:, 2:] += boxes[:, :2]\n",
    "        \n",
    "        labels = torch.as_tensor([obj['category_id'] for obj in target], dtype=torch.int64)\n",
    "        image_id = torch.tensor([image_id])\n",
    "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "        iscrowd = torch.zeros((len(target),), dtype=torch.int64)\n",
    "\n",
    "        formatted_target = {\n",
    "            \"boxes\": boxes,\n",
    "            \"labels\": labels,\n",
    "            \"image_id\": image_id,\n",
    "            \"area\": area,\n",
    "            \"iscrowd\": iscrowd\n",
    "        }\n",
    "        \n",
    "        # -- Logic Augmentation được tích hợp ở đây --\n",
    "        if self.train:\n",
    "            # Random horizontal flip với xác suất 50%\n",
    "            if random.random() < 0.5:\n",
    "                # Lật ảnh\n",
    "                img = F.hflip(img)\n",
    "                \n",
    "                # Lật các bounding box\n",
    "                bbox = formatted_target[\"boxes\"]\n",
    "                # Tọa độ x_min mới = chiều rộng ảnh - x_max cũ\n",
    "                # Tọa độ x_max mới = chiều rộng ảnh - x_min cũ\n",
    "                bbox[:, [0, 2]] = image_width - bbox[:, [2, 0]]\n",
    "                formatted_target[\"boxes\"] = bbox\n",
    "\n",
    "        # Cuối cùng, chuyển ảnh sang Tensor\n",
    "        img = F.to_tensor(img)\n",
    "\n",
    "        return img, formatted_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_transform(train):\n",
    "    transforms = []\n",
    "    # converts the image, a PIL image, into a PyTorch Tensor\n",
    "    if train:\n",
    "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "    return T.Compose(transforms) if transforms else None\n",
    "\n",
    "\n",
    "# --- 3. Model Definition ---\n",
    "def get_model(num_classes):\n",
    "    # load a model pre-trained on COCO\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights=\"DEFAULT\", pretrain = True)\n",
    "\n",
    "    # get number of input features for the classifier\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    # replace the pre-trained head with a new one\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "    return model\n",
    "\n",
    "# --- 4. Collate Function for Dataloader ---\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-07-15T15:19:03.732Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    train_img = os.path.join(root_folder, 'train2017')\n",
    "    train_ann = os.path.join(root_folder, '')\n",
    "\n",
    "    val_img = os.path.join(root_folder, 'val2017')\n",
    "    val_ann = os.path.join(root_folder, '')\n",
    "\n",
    "    dataset = CocoDetectionDataset(train_img, train_ann, train=True)\n",
    "    dataset_val = CocoDetectionDataset(val_img, val_ann, train=False)\n",
    "\n",
    "    data_loader = DataLoader(\n",
    "        dataset, batch_size=8, shuffle=True, num_workers=4, collate_fn=collate_fn\n",
    "    )\n",
    "\n",
    "    data_loader_val = DataLoader(\n",
    "        dataset_val, batch_size=4, shuffle= False, num_workers=4, collate_fn=collate_fn\n",
    "    )\n",
    "\n",
    "    device = torch.device('cuda')if torch.cuda.is_available() else torch.device('cpu')\n",
    "    num_classes = 91 + 1\n",
    "    model = get_model(num_classes)\n",
    "    model.to(device)\n",
    "\n",
    "    params = [p for p in model.parameters() if p.requires_grad]\n",
    "    optimizer = torch.optim.SGD(params, lr=0.01, momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "    num_epochs = 30\n",
    "    patience = 5\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_path = '/kaggle/working/fasterrcnn_best_model.pth'\n",
    "    \n",
    "    print(\"Bắt đầu quá trình training...\")\n",
    "    for epoch in range(num_epochs):\n",
    "        # --- Training ---\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        train_loop = tqdm(data_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Training]\")\n",
    "        \n",
    "        for images, targets in train_loop:\n",
    "            images = list(image.to(device) for image in images)\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "    \n",
    "            loss_dict = model(images, targets)\n",
    "            losses = sum(loss for loss in loss_dict.values())\n",
    "    \n",
    "            optimizer.zero_grad()\n",
    "            losses.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            current_loss = losses.item()\n",
    "            total_train_loss += current_loss\n",
    "            \n",
    "            # Cập nhật thông tin loss lên thanh tiến trình\n",
    "            train_loop.set_postfix(loss=f\"{current_loss:.4f}\")\n",
    "        \n",
    "        avg_train_loss = total_train_loss / len(data_loader)\n",
    "    \n",
    "        # --- Validation ---\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "        # Tạo đối tượng tqdm cho validation\n",
    "        val_loop = tqdm(data_loader_val, desc=f\"Epoch {epoch+1}/{num_epochs} [Validation]\")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, targets in val_loop:\n",
    "                images = list(image.to(device) for image in images)\n",
    "                targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "                \n",
    "                loss_dict_val = model(images, targets)\n",
    "                losses_val = sum(loss for loss in loss_dict_val.values())\n",
    "                \n",
    "                current_val_loss = losses_val.item()\n",
    "                total_val_loss += current_val_loss\n",
    "                \n",
    "                # Cập nhật thông tin val_loss lên thanh tiến trình\n",
    "                val_loop.set_postfix(val_loss=f\"{current_val_loss:.4f}\")\n",
    "                \n",
    "        avg_val_loss = total_val_loss / len(data_loader_val)\n",
    "        \n",
    "        # In kết quả trung bình của epoch\n",
    "        print(f\"\\nEpoch #{epoch+1} Summary: Avg Train Loss: {avg_train_loss:.4f} | Avg Val Loss: {avg_val_loss:.4f}\")\n",
    "    \n",
    "        # --- Logic Early Stopping và lưu mô hình tốt nhất ---\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            epochs_no_improve = 0\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            print(f\"-> Validation loss cải thiện. Đã lưu mô hình tốt nhất vào '{best_model_path}'\\n\")\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            print(f\"-> Validation loss không cải thiện. Đã {epochs_no_improve}/{patience} epoch không cải thiện.\\n\")\n",
    "    \n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f\"Early stopping! Dừng training vì validation loss không cải thiện trong {patience} epoch.\")\n",
    "            break\n",
    "    \n",
    "    print(\"\\nHoàn tất training!\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 857191,
     "sourceId": 1462296,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
